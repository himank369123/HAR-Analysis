trainset<-read.csv("C:/Users/himank/Documents/R/ml course proj/pml-training.csv")
testing<-read.csv("C:/Users/himank/Documents/R/ml course proj/pml-testing.csv")
trainset
dim(trainset)
ncol(trainset)
str(trainset)
trainset$classe
sum(is.na(trainset$amplitude_roll_arm))
table(trainset$classe)
library(caret)
set.seed(123)
partition<-createDataPartition(y=trainset$classe,p=0.75,list=F)
training<-trainset[partition,]
validation<-trainset[-partition,]
training<-training[,-nearZeroVar(training)]
names(training)
#removing id and username colums
training<-training[,-]
#removing id and username colums
training<-training[,-c(1,2)]
names(training)
names(training)
training[,102]
##Pca :
prepr<-preProcess(training[,-102])
##Pca :
prepr<-preProcess(training[,-102],mmethod = 'pca',thresh=0.8)
prepr
prepr$rotation
prepr
##Pca :
prepr<-preProcess(training[,-102],mmethod = 'pca',thresh=0.8)
prepr
##Pca :
prepr<-preProcess(training[,-102],mmethod = 'pca',thresh=0.9)
##Pca :
prepr<-preProcess(training[,-102],mmethod = 'pca',thresh=0.9)
##Pca
prepr<-preProcess(training[,-102],mmethod = 'pca',thresh=0.9)
#Pca
prepr<-preProcess(training[,-102],mmethod = 'pca',thresh=0.9)
prepr<-preProcess(training[,-102],mmethod = 'pca',thresh=0.9)
prepr
prepr$rotation
prepr
prepr$rotation
summary(prepr)
prcomp()
prcomp(training[,-102])
prepr<-preProcess(training[,-102],mmethod = 'pca',thresh=0.9)
summary(prepr)
fviz.eig(0)
library(factoextra)
install.packages("factoextra")
library(factoextra)
fviz.eig(prepr)
fviz_eig(prepr)
prcomp(training[,-102])
fviz_eig(prcomp(training[,-102]))
prepr<-preProcess(training[,-102],mmethod = 'pca',pcaComp = 25)
prepr
prepr$rotation
predict(prepr,training[,-102])
modelrp<-train(classe~.,training,method='rpart')
predictrp<-predict(modelrp,testing)
predictrp
predictrp<-predict(modelrp,testing)
modelrp<-train(classe~.,training,method='rpart')
predictrp<-predict(modelrp,testing)
names(training)
training$classe
any(is,na(training$classe))
any(is.na(training$classe))
class(training$classe)
training <- training[,-Cl]
#removing descriptive cols:
Cl <- grep("name|timestamp|window|X", colnames(training), value=F)
training <- training[,-Cl]
names(training)
#removing cols with more than
trainingCl[trainingCl==""] <- NA
#removing cols with more than
training[training==""] <- NA
naproportion<-sapply(training,2,function(x) sum(is.na(x))/nrow(training))
naproportion<-sapply(training,2,function(x) sum(is.na(x))/nrow(training))
naproportion<-sapply(training,function(x) sum(is.na(x))/nrow(training))
training<-training[!(naproportion>80)]
names(training)
training<-training[!(naproportion>50)]
names(training)
training<-training[!(naproportion>10)]
names(training)
training<-training[!(naproportion>1)]
names(training)
training<-training[!(naproportion>0.80)]
names(training)
prepr<-preProcess(training[,-102],mmethod = 'pca',pcaComp = 25)
predict(prepr,training[,-102])
names(training)
#Pca
prepr<-preProcess(training[,-53],mmethod = 'pca',pcaComp = 25)
#Pca
prepr<-preProcess(training[,-53],mmethod = 'pca',thresh = 0.8)
prepr$rotation
modelrp<-train(classe~.,training,method='rpart')
predictrp<-predict(modelrp,testing)
predictrp
class(training$classe)
modelrp
importance(modelrp)
modelrf<-train(classe~.,training,method='rf')
training
modelrf
modelrf<-train(classe~.,training,method='rf',ntrees=10)
modelrf<-train(classe~.,training,method='rf',ntrees=2)
training
#Pca
prepr<-preProcess(training[,-53],method = 'pca',thresh = 0.8)
prepr$rotation
summary(prepr)
prepr$rotation
#Pca
prepr<-preProcess(training[,-53],method = 'pca',thresh = 0.95)
prepr$rotation
trainingPC<-predict(prepr,training[,-53])
modelrp<-train(classe~.,training,method='rpart')
modelrp
modelrppc<-train(training$classe~.,data=trainingPC,method='rpart')
modelrppc
modelrppc<-train(training$classe~.,data=trainingPC,method='rpart')
names(training)
modelrp<-train(classe~.,training,method='rpart')
confusionMatrix(predict(modelrp,validation),validation$classe)
trainset<-read.csv("C:/Users/himank/Documents/R/ml course proj/pml-training.csv")
testing<-read.csv("C:/Users/himank/Documents/R/ml course proj/pml-testing.csv")
trainset
library(caret)
set.seed(123)
trainset<-read.csv("C:/Users/himank/Documents/R/ml course proj/pml-training.csv")
testing<-read.csv("C:/Users/himank/Documents/R/ml course proj/pml-testing.csv")
trainset
dim(trainset)
ncol(trainset)
str(trainset)
trainset$classe
sum(is.na(trainset$amplitude_roll_arm))
table(trainset$classe)
partition<-createDataPartition(y=trainset$classe,p=0.75,list=F)
training<-trainset[partition,]
validation<-trainset[-partition,]
training<-training[,-nearZeroVar(training)]
names(training)
#removing id and username colums
training<-training[,-c(1,2)]
names(training)
table(trainset$classe)
partition<-createDataPartition(y=trainset$classe,p=0.75,list=F)
training<-trainset[partition,]
validation<-trainset[-partition,]
training<-training[,-nearZeroVar(training)]
names(training)
#removing id and username colums
training<-training[,-c(1,2)]
names(training)
#removing descriptive cols:
Cl <- grep("name|timestamp|window|X", colnames(training), value=F)
training <- training[,-Cl]
#removing cols with more than 80%
training[training==""] <- NA
naproportion<-sapply(training,function(x) sum(is.na(x))/nrow(training))
training<-training[!(naproportion>0.60)]
names(training)
CL
Cl
#removing descriptive cols:
Cl<-c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2",
"cvtd_timestamp", "new_window", "num_window")
library(caret)
set.seed(123)
trainset<-read.csv("C:/Users/himank/Documents/R/ml course proj/pml-training.csv")
testing<-read.csv("C:/Users/himank/Documents/R/ml course proj/pml-testing.csv")
trainset
dim(trainset)
ncol(trainset)
str(trainset)
trainset$classe
table(trainset$classe)
partition<-createDataPartition(y=trainset$classe,p=0.75,list=F)
training<-trainset[partition,]
validation<-trainset[-partition,]
training<-training[,-nearZeroVar(training)]
names(training)
#removing descriptive cols:
Cl<-c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2",
"cvtd_timestamp", "new_window", "num_window")
training <- training[,-Cl]
#removing descriptive cols:
Cl<-c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2",
"cvtd_timestamp", "new_window", "num_window")
Cl
training <- training[,-Cl]
training <- training[,!Cl]
training <- training[,!names(training) %in% Cl]
names(training)
#removing cols with more than 80%
training[training==""] <- NA
naproportion<-sapply(training,function(x) sum(is.na(x))/nrow(training))
training<-training[!(naproportion>0.60)]
names(training)
rfModel <- randomForest(classe ~ ., data = training, importance = TRUE, ntrees = 10)
library(randomForest)
rfModel <- randomForest(classe ~ ., data = training, importance = TRUE, ntrees = 10)
ptraining <- predict(rfModel, training)
print(confusionMatrix(ptraining, training$classe))
train(classe~.,data=training,ntree=10)
mod<-train(classe~.,data=training,ntree=10)
pre<-predict(mod,training)
print(confusionMatrix(pred,training$classe))
print(confusionMatrix(pre,training$classe))
modelrf<-train(classe~.,data=training,ntree=10)
predectrf<-predict(mod,training)
print(confusionMatrix(pre,training$classe))
predectrf<-predict(modelrf,training)
predictrf<-predict(modelrf,training)
print(confusionMatrix(predictrf,training$classe))
modelrf<-train(classe~.,data=training,method='rf',ntree=10)
predictrf<-predict(modelrf,training)
print(confusionMatrix(predictrf,training$classe))
predictrf<-predict(modelrf,training)
print(confusionMatrix(predictrf,training$classe))
#decision tree
modelrp<-train(classe~.,data=training,method='rpart')
predictrp<-predict(modelrp,training)
print(confusionMatrix(predictrp,training$classe))
#boosted classification tree
modelgbm<-train(classe~.data=training,method='gbm')
#boosted classification tree
modelgbm<-train(classe~.,data=training,method='gbm')
#boosted classification tree
?gbm
modelgbm<-train(classe~.,data=training,method='gbm',ntree=2)
?trainControl
predictgbm<-predict(modelgbm,training)
#boosted classification tree
tr<-trainControl(method='gbm',number=2,ntree=2)
#boosted classification tree
tr<-trainControl(method='gbm',number=2,repeats = 0)
#boosted classification tree
tr<-trainControl(method='gbm',number=2)
modelgbm<-train(classe~.,data=training,method='gbm',trainControl=tr)
install.packages("rattle")
predictgbm<-predict(modelgbm,training)
print(confusionMatrix(predictgbm,training$classe))
#decision tree
library(rattle)
fancyRpartPlot(modelrp)
fancyRpartPlot(modelrp$finalModel)
